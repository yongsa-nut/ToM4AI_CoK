{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7caa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d58a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "models = [\"gpt-5-low\",\"gpt-5-medium\",\"gpt-5-high\",\"gpt-4o\",\"gpt-4o-mini\"]\n",
    "names = [(\"Vicki\", \"Denise\")]  # Only one name pair to save cost\n",
    "colors = [(\"blue\",\"purple\",\"red\",\"green\"), (\"green\",\"red\",\"blue\",\"purple\")] # the second color order was changed due to images generated in this new order instead\n",
    "conditions = [\"Ignorance\", \"Knowledge-plausible\", \"Knowledge-implausible\"]\n",
    "instruments = [\"violin\",\"flute\",\"ball\"]\n",
    "trials = list(range(5))\n",
    "\n",
    "# Function to encode image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to generate the multimodal stimulus\n",
    "def generate_stimulus(condition, names, colors, instrument):\n",
    "    \"\"\"Generate multimodal stimulus with text and images.\n",
    "    \n",
    "    Returns a list of content items for the OpenAI API.\n",
    "    \"\"\"\n",
    "    # Condition-specific text\n",
    "    if condition == \"Ignorance\":\n",
    "        cond_statement = f\"moves the {instrument} to another container.\"\n",
    "    elif condition == \"Knowledge-plausible\":\n",
    "        cond_statement = f\"moves the {instrument} to the {colors[2]} container.\"\n",
    "    elif condition == \"Knowledge-implausible\":\n",
    "        cond_statement = f\"moves the {instrument} to the {colors[1]} container.\"\n",
    "    \n",
    "    # Image paths\n",
    "    color_str = f\"{colors[0]}-{colors[1]}-{colors[2]}-{colors[3]}\"\n",
    "    first_image_path = f\"images/first-{instrument}-{color_str}.jpg\"\n",
    "    second_image_path = f\"images/second-{instrument}-{color_str}.jpg\"\n",
    "    \n",
    "    # Encode images\n",
    "    first_image_b64 = encode_image(first_image_path)\n",
    "    second_image_b64 = encode_image(second_image_path)\n",
    "    \n",
    "    # Build multimodal content\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": f\"This is {names[0]}. She finishes playing her {instrument} and puts it in the {colors[0]} container. Then she goes outside to play.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"input_image\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{first_image_b64}\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": f\"While {names[0]} is outside playing, her sister, {names[1]} {cond_statement}\\nThen, {names[1]} rearranges the containers in the room until the room looks like the picture below.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"input_image\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{second_image_b64}\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": f\"\"\"When {names[0]} returns, she wants to play her {instrument}.\n",
    "What are the chances {names[0]} will first look for her {instrument} in each of the above containers?\n",
    "Put your answer in percentages (must sum to 100) in the JSON structure inside <answer> tags like below:\n",
    "<answer>\n",
    "{{\n",
    "    \\\"{colors[0]}\\\": ___,\n",
    "    \\\"{colors[1]}\\\": ___,\n",
    "    \\\"{colors[2]}\\\": ___,\n",
    "    \\\"{colors[3]}\\\": ___\n",
    "}}\n",
    "</answer>\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Function to generate text-only stimulus description (for CSV storage)\n",
    "def generate_stimulus_description(condition, names, colors, instrument):\n",
    "    \"\"\"Generate a text description of the stimulus for CSV storage.\"\"\"\n",
    "    color_str = f\"{colors[0]}-{colors[1]}-{colors[2]}-{colors[3]}\"\n",
    "    return f\"[IMAGE STIMULUS] names={names}, colors={colors}, instrument={instrument}, condition={condition}, images=first-{instrument}-{color_str}.jpg + second-{instrument}-{color_str}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba03ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 450 stimuli\n"
     ]
    }
   ],
   "source": [
    "# Generate the initial DataFrame\n",
    "data = []\n",
    "\n",
    "for model, name_pair, color_set, condition, instrument, trial in product(\n",
    "    models, names, colors, conditions, instruments, trials\n",
    "):\n",
    "    stimulus_desc = generate_stimulus_description(condition, name_pair, color_set, instrument)\n",
    "    data.append({\n",
    "        \"names\": name_pair,\n",
    "        \"colors\": color_set,\n",
    "        \"condition\": condition,\n",
    "        \"model\": model,\n",
    "        \"instrument\": instrument,\n",
    "        \"trial\": trial,\n",
    "        \"stimulus\": stimulus_desc\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Generated {len(df)} stimuli\")\n",
    "df.to_csv(\"stimuli_image.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bdfaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "def generate_openai_image(content, model=\"gpt-5\"):\n",
    "    \"\"\"Call OpenAI API with multimodal content (text + images).\"\"\"\n",
    "    \n",
    "    reasoning = {}\n",
    "    model_name = model\n",
    "    if \"gpt-5\" in model:\n",
    "        reasoning = {\n",
    "            \"effort\": model.split(\"-\")[-1],\n",
    "            \"summary\": \"detailed\"\n",
    "        }\n",
    "        model_name = \"gpt-5\"\n",
    "    \n",
    "    client = OpenAI()\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }\n",
    "        ],\n",
    "        reasoning=reasoning if reasoning else None,\n",
    "        store=True,\n",
    "        temperature=1\n",
    "    )\n",
    "    \n",
    "    # Extract reasoning summary if available\n",
    "    reasoning_summary = \"\"\n",
    "    if hasattr(response, 'output') and len(response.output) > 0:\n",
    "        if hasattr(response.output[0], 'summary') and len(response.output[0].summary) > 0:\n",
    "            reasoning_summary = response.output[0].summary[0].text\n",
    "    \n",
    "    return response.output_text, reasoning_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9102852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 450 stimuli\n"
     ]
    }
   ],
   "source": [
    "# Load the stimuli and prepare for results\n",
    "results_df = pd.read_csv(\"stimuli_image.csv\")\n",
    "results_df['result'] = \"\"  # Placeholder for model responses\n",
    "results_df['reasoning'] = \"\"  # Placeholder for reasoning content\n",
    "print(f\"Loaded {len(results_df)} stimuli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partial results if any\n",
    "results_df = pd.read_csv(\"model_responses_partial_image.csv\")\n",
    "print(f\"Resuming from {len(results_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4687561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows...\n",
      "Processed 30 rows...\n",
      "Processed 60 rows...\n",
      "Processed 90 rows...\n",
      "Processed 120 rows...\n",
      "Processed 150 rows...\n",
      "Processed 180 rows...\n",
      "Processed 210 rows...\n",
      "Processed 240 rows...\n",
      "Processed 270 rows...\n",
      "Processed 300 rows...\n",
      "Processed 330 rows...\n",
      "Processed 360 rows...\n",
      "Processed 390 rows...\n",
      "Processed 420 rows...\n",
      "Done! Saved 450 results.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each row and get model responses\n",
    "for index, row in results_df.iterrows():\n",
    "    # Skip if already processed\n",
    "    if row['result'] != \"\" and pd.notna(row['result']):\n",
    "        continue\n",
    "    \n",
    "    # Generate multimodal content on-the-fly\n",
    "    names = eval(row['names'])  # Convert string tuple back to tuple\n",
    "    colors = eval(row['colors'])\n",
    "    condition = row['condition']\n",
    "    instrument = row['instrument']\n",
    "    model = row['model']\n",
    "    \n",
    "    content = generate_stimulus(condition, names, colors, instrument)\n",
    "    response = generate_openai_image(content, model=model)\n",
    "    \n",
    "    results_df.at[index, 'result'] = response[0]\n",
    "    results_df.at[index, 'reasoning'] = response[1]\n",
    "    \n",
    "    # Save the results to a new CSV file every 30 rows\n",
    "    if index % 30 == 0:\n",
    "        print(f\"Processed {index} rows...\")\n",
    "        results_df.to_csv(\"model_responses_partial_image.csv\", index=False)\n",
    "\n",
    "# Save the final results to a CSV file\n",
    "results_df.to_csv(\"model_responses_image.csv\", index=False)\n",
    "print(f\"Done! Saved {len(results_df)} results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
